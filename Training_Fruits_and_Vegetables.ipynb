{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJfrv8kmvaxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f780618-9c80-4a29-c8bb-e26f202f51cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoKOrb4o1c1y"
      },
      "source": [
        "\n",
        "# **Impoerting libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbJHIdyct6Zx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HblEU-9n1uQd"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysmo4Rrj2dFK"
      },
      "source": [
        "# Training Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDpI6hbu2itV",
        "outputId": "f328c36f-1685-4853-c1fb-4dce8cbe673b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3115 files belonging to 36 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/project/Fruits_and_Vegetables_Recognition_System/train',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64,64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpxXd9t23xsv"
      },
      "source": [
        "# Validation Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXiswVxi32kE",
        "outputId": "fdd380d8-90ce-4381-c12d-ab320621fc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 351 files belonging to 36 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/project/Fruits_and_Vegetables_Recognition_System/validation',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64,64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_bqGEqs6rjm"
      },
      "source": [
        "# **Building Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnNCHDZe6yT_"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOST0p7-7NvV"
      },
      "source": [
        "# Building Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_8qTuX37VqC"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIPSf3_88Bsc"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC5bFQMY8Qga"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHWy1s4w8Y_D"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwrNJvlS8jM6"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5)) # To avoid overfitting"
      ],
      "metadata": {
        "id": "udgKaWxo8SYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output layers\n",
        "cnn.add(tf.keras.layers.Dense(units=36, activation='softmax'))"
      ],
      "metadata": {
        "id": "w19adrE88pfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--kK7Yuo87n6"
      },
      "source": [
        "# **Compiling and Training Phase**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG52TzCi8xkC"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuyIBISM7ifD",
        "outputId": "91f1c5d9-0109-455c-fe17-584870f4e193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 30, 30, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10816)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               5538304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 36)                9252      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5744452 (21.91 MB)\n",
            "Trainable params: 5744452 (21.91 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhVWMMBM9e4V",
        "outputId": "00bfeb8e-2051-4365-b41b-fc6d93c86b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "98/98 [==============================] - 260s 2s/step - loss: 6.3751 - accuracy: 0.0334 - val_loss: 3.5736 - val_accuracy: 0.0427\n",
            "Epoch 2/30\n",
            "98/98 [==============================] - 151s 1s/step - loss: 3.8682 - accuracy: 0.0311 - val_loss: 3.5429 - val_accuracy: 0.0627\n",
            "Epoch 3/30\n",
            "98/98 [==============================] - 151s 1s/step - loss: 3.7060 - accuracy: 0.0539 - val_loss: 3.3637 - val_accuracy: 0.1026\n",
            "Epoch 4/30\n",
            "98/98 [==============================] - 152s 1s/step - loss: 3.5358 - accuracy: 0.0780 - val_loss: 3.1917 - val_accuracy: 0.1282\n",
            "Epoch 5/30\n",
            "98/98 [==============================] - 142s 1s/step - loss: 3.2180 - accuracy: 0.1284 - val_loss: 2.9694 - val_accuracy: 0.2108\n",
            "Epoch 6/30\n",
            "98/98 [==============================] - 141s 1s/step - loss: 2.8598 - accuracy: 0.2215 - val_loss: 1.9399 - val_accuracy: 0.4672\n",
            "Epoch 7/30\n",
            "98/98 [==============================] - 151s 1s/step - loss: 2.3182 - accuracy: 0.3541 - val_loss: 1.2756 - val_accuracy: 0.6809\n",
            "Epoch 8/30\n",
            "98/98 [==============================] - 149s 1s/step - loss: 1.7387 - accuracy: 0.5255 - val_loss: 1.0274 - val_accuracy: 0.7749\n",
            "Epoch 9/30\n",
            "98/98 [==============================] - 151s 1s/step - loss: 1.1333 - accuracy: 0.6796 - val_loss: 0.4095 - val_accuracy: 0.9088\n",
            "Epoch 10/30\n",
            "98/98 [==============================] - 151s 1s/step - loss: 0.7138 - accuracy: 0.7952 - val_loss: 0.4169 - val_accuracy: 0.9516\n",
            "Epoch 11/30\n",
            "98/98 [==============================] - 149s 1s/step - loss: 0.5365 - accuracy: 0.8587 - val_loss: 0.4788 - val_accuracy: 0.9402\n",
            "Epoch 12/30\n",
            "98/98 [==============================] - 142s 1s/step - loss: 0.4373 - accuracy: 0.8915 - val_loss: 0.4191 - val_accuracy: 0.9601\n",
            "Epoch 13/30\n",
            "98/98 [==============================] - 150s 1s/step - loss: 0.3233 - accuracy: 0.9159 - val_loss: 0.4046 - val_accuracy: 0.9573\n",
            "Epoch 14/30\n",
            "98/98 [==============================] - 150s 1s/step - loss: 0.3177 - accuracy: 0.9223 - val_loss: 0.3830 - val_accuracy: 0.9487\n",
            "Epoch 15/30\n",
            "98/98 [==============================] - 143s 1s/step - loss: 0.2485 - accuracy: 0.9352 - val_loss: 0.3608 - val_accuracy: 0.9544\n",
            "Epoch 16/30\n",
            "98/98 [==============================] - 140s 1s/step - loss: 0.3044 - accuracy: 0.9406 - val_loss: 0.3762 - val_accuracy: 0.9658\n",
            "Epoch 17/30\n",
            "98/98 [==============================] - 139s 1s/step - loss: 0.2271 - accuracy: 0.9483 - val_loss: 0.4358 - val_accuracy: 0.9544\n",
            "Epoch 18/30\n",
            "98/98 [==============================] - 148s 1s/step - loss: 0.2163 - accuracy: 0.9467 - val_loss: 0.4965 - val_accuracy: 0.9601\n",
            "Epoch 19/30\n",
            "98/98 [==============================] - 140s 1s/step - loss: 0.1839 - accuracy: 0.9567 - val_loss: 0.5346 - val_accuracy: 0.9601\n",
            "Epoch 20/30\n",
            "98/98 [==============================] - 138s 1s/step - loss: 0.1648 - accuracy: 0.9631 - val_loss: 1.0057 - val_accuracy: 0.9202\n",
            "Epoch 21/30\n",
            "98/98 [==============================] - 140s 1s/step - loss: 0.2148 - accuracy: 0.9531 - val_loss: 0.3460 - val_accuracy: 0.9630\n",
            "Epoch 22/30\n",
            "98/98 [==============================] - 147s 1s/step - loss: 0.1784 - accuracy: 0.9583 - val_loss: 0.3586 - val_accuracy: 0.9544\n",
            "Epoch 23/30\n",
            "98/98 [==============================] - 147s 1s/step - loss: 0.1973 - accuracy: 0.9563 - val_loss: 0.3326 - val_accuracy: 0.9658\n",
            "Epoch 24/30\n",
            "98/98 [==============================] - 149s 1s/step - loss: 0.1920 - accuracy: 0.9615 - val_loss: 0.4097 - val_accuracy: 0.9573\n",
            "Epoch 25/30\n",
            "98/98 [==============================] - 147s 1s/step - loss: 0.1489 - accuracy: 0.9679 - val_loss: 0.6965 - val_accuracy: 0.9516\n",
            "Epoch 26/30\n",
            "98/98 [==============================] - 147s 1s/step - loss: 0.1910 - accuracy: 0.9570 - val_loss: 0.5338 - val_accuracy: 0.9573\n",
            "Epoch 27/30\n",
            "98/98 [==============================] - 139s 1s/step - loss: 0.2061 - accuracy: 0.9586 - val_loss: 0.4856 - val_accuracy: 0.9573\n",
            "Epoch 28/30\n",
            "98/98 [==============================] - 139s 1s/step - loss: 0.1542 - accuracy: 0.9692 - val_loss: 0.4173 - val_accuracy: 0.9630\n",
            "Epoch 29/30\n",
            "98/98 [==============================] - 140s 1s/step - loss: 0.1632 - accuracy: 0.9692 - val_loss: 0.5667 - val_accuracy: 0.9573\n",
            "Epoch 30/30\n",
            "98/98 [==============================] - 148s 1s/step - loss: 0.1587 - accuracy: 0.9701 - val_loss: 0.6501 - val_accuracy: 0.9601\n"
          ]
        }
      ],
      "source": [
        "training_history = cnn.fit(x=training_set, validation_data=validation_set, epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model"
      ],
      "metadata": {
        "id": "BbV51qTfyuej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdq1IJAq9ygp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d112245-8fea-43ab-df09-afcbbb73089f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "cnn.save('/content/drive/MyDrive/project/Fruits_and_Vegetables_Recognition_System/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_history.history"
      ],
      "metadata": {
        "id": "0yY824SLy2g3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee72c75-fd53-4932-e5d9-9dc878d75741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [6.375114917755127,\n",
              "  3.8682374954223633,\n",
              "  3.7059667110443115,\n",
              "  3.5357797145843506,\n",
              "  3.217953681945801,\n",
              "  2.859785318374634,\n",
              "  2.318204879760742,\n",
              "  1.7386947870254517,\n",
              "  1.1332905292510986,\n",
              "  0.7138174176216125,\n",
              "  0.5364782810211182,\n",
              "  0.4373006224632263,\n",
              "  0.323263019323349,\n",
              "  0.3176514208316803,\n",
              "  0.2485484480857849,\n",
              "  0.3043934106826782,\n",
              "  0.22705276310443878,\n",
              "  0.21632954478263855,\n",
              "  0.18393586575984955,\n",
              "  0.16481627523899078,\n",
              "  0.2147584706544876,\n",
              "  0.17839090526103973,\n",
              "  0.19732603430747986,\n",
              "  0.1919596642255783,\n",
              "  0.14887580275535583,\n",
              "  0.19100135564804077,\n",
              "  0.2061012238264084,\n",
              "  0.1542074978351593,\n",
              "  0.1632038801908493,\n",
              "  0.15869897603988647],\n",
              " 'accuracy': [0.03338683769106865,\n",
              "  0.031139647588133812,\n",
              "  0.05393258482217789,\n",
              "  0.07800962775945663,\n",
              "  0.1284109205007553,\n",
              "  0.22150883078575134,\n",
              "  0.35409310460090637,\n",
              "  0.5255216956138611,\n",
              "  0.679614782333374,\n",
              "  0.7951846122741699,\n",
              "  0.8587480187416077,\n",
              "  0.8914927840232849,\n",
              "  0.9158908724784851,\n",
              "  0.9223114252090454,\n",
              "  0.9351524710655212,\n",
              "  0.9406099319458008,\n",
              "  0.9483146071434021,\n",
              "  0.9467094540596008,\n",
              "  0.9566613435745239,\n",
              "  0.9630818367004395,\n",
              "  0.9531300067901611,\n",
              "  0.9582664370536804,\n",
              "  0.9563403129577637,\n",
              "  0.961476743221283,\n",
              "  0.9678972959518433,\n",
              "  0.9569823145866394,\n",
              "  0.9585874676704407,\n",
              "  0.9691813588142395,\n",
              "  0.9691813588142395,\n",
              "  0.9701444506645203],\n",
              " 'val_loss': [3.573617696762085,\n",
              "  3.542881488800049,\n",
              "  3.3636696338653564,\n",
              "  3.1917102336883545,\n",
              "  2.9693753719329834,\n",
              "  1.939875841140747,\n",
              "  1.2755935192108154,\n",
              "  1.0273550748825073,\n",
              "  0.4094906747341156,\n",
              "  0.4169059097766876,\n",
              "  0.47881248593330383,\n",
              "  0.4191106855869293,\n",
              "  0.40461987257003784,\n",
              "  0.3830317258834839,\n",
              "  0.3608247935771942,\n",
              "  0.37618422508239746,\n",
              "  0.4358304738998413,\n",
              "  0.4964645802974701,\n",
              "  0.5346406698226929,\n",
              "  1.0056796073913574,\n",
              "  0.3460296094417572,\n",
              "  0.3586146831512451,\n",
              "  0.33259695768356323,\n",
              "  0.4096764028072357,\n",
              "  0.6965091824531555,\n",
              "  0.5337978005409241,\n",
              "  0.4855874478816986,\n",
              "  0.4173033535480499,\n",
              "  0.5666901469230652,\n",
              "  0.6500831246376038],\n",
              " 'val_accuracy': [0.04273504391312599,\n",
              "  0.06267806142568588,\n",
              "  0.10256410390138626,\n",
              "  0.12820513546466827,\n",
              "  0.21082621812820435,\n",
              "  0.4672364592552185,\n",
              "  0.680911660194397,\n",
              "  0.7749287486076355,\n",
              "  0.9088318943977356,\n",
              "  0.9515669345855713,\n",
              "  0.94017094373703,\n",
              "  0.9601139426231384,\n",
              "  0.9572649598121643,\n",
              "  0.9487179517745972,\n",
              "  0.9544159770011902,\n",
              "  0.9658119678497314,\n",
              "  0.9544159770011902,\n",
              "  0.9601139426231384,\n",
              "  0.9601139426231384,\n",
              "  0.9202279448509216,\n",
              "  0.9629629850387573,\n",
              "  0.9544159770011902,\n",
              "  0.9658119678497314,\n",
              "  0.9572649598121643,\n",
              "  0.9515669345855713,\n",
              "  0.9572649598121643,\n",
              "  0.9572649598121643,\n",
              "  0.9629629850387573,\n",
              "  0.9572649598121643,\n",
              "  0.9601139426231384]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recording History\n",
        "import json\n",
        "with open('/content/drive/MyDrive/project/Fruits_and_Vegetables_Recognition_System/training_history.json', 'w') as f:\n",
        "    json.dump(training_history.history, f)"
      ],
      "metadata": {
        "id": "YqdAgNbZzEKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_history.history.keys())"
      ],
      "metadata": {
        "id": "T26sLP8-zYbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculating Accuracy of Model Achieved on Validation set**"
      ],
      "metadata": {
        "id": "ms8jM4UyzyF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation set Accuracy: {} % \",training_history.history['val_accuracy'][-1]*100)"
      ],
      "metadata": {
        "id": "-TlF4mvPzss4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accuracy Visualization**"
      ],
      "metadata": {
        "id": "kKrlPCrJ07Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Visualization"
      ],
      "metadata": {
        "id": "y_T3Jr0o1Et3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epocha = [i for i in range(1,33)]\n",
        "plt.plot(epocha, training_history.history['accuracy'], color='red')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Training Accuracy')\n",
        "plt.title('Visualization of Training Accuracy Result')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lrUO1Ft-0FUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation Accuracy"
      ],
      "metadata": {
        "id": "p3yeP4lg152X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epocha, training_history.history['val_accuracy'],color='blue')\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Visualization of Validation Accuracy Result')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UNidIRJM1vhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.evaluate(training_set)"
      ],
      "metadata": {
        "id": "Yt7nn1WC93h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.evaluate(validation_set)"
      ],
      "metadata": {
        "id": "qRXyGw-49-WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test set Evaluation**"
      ],
      "metadata": {
        "id": "QtqLQK0K_KJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/project/Fruits_and_Vegetables_Recognition_System/test',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64,64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "id": "kRfy8hA-2NgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_acc = cnn.evaluate(test_set)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "hS7TciWL_Vd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}